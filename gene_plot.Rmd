---
title: "gene subtype classification"
author: "Jae Kwan Koo"
output:
  html_document:
    df_print: paged
    code_folding: show
    fig_height: 6
    fig_width: 10
    highlight: textmate
  word_document: default
  github_document:
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = T)
```  

## Library  

```{r warning=F, message=FALSE}
# Manipulate
library(tidyverse)
library(data.table)
library(glue)

# Model
library(glmnet)
library(caret)
library(Metrics)
library(ROSE) # rose
library(DMwR) # smote
library(ggfortify) # pca 

# Parallel
library(doParallel)

# Visualization
library(hrbrthemes)
library(viridis)
library(plotROC) # plot the ROC curve
library(pROC)
library(patchwork)
```  
```{r echo=FALSE}
load("D:/Jae Kwan/4학년여름/연구생/연구주제/glm_model_gridsearch.RData")
```  

## Parallel processing  

```{r}
doParallel::registerDoParallel(3)
```  


## One hot encoding  

```{r}
one_hot_meta_dat <- model.matrix(~.-1, meta_dat)
colnames(one_hot_meta_dat) <- one_hot_meta_dat %>% colnames %>% 
  str_remove(.,"condition")
```  

## GLM  

```{r}
normal_t <- normal %>% t %>% as.matrix
normal_t[1:3,1:2]
dim(normal_t)


cancer_fit <- glmnet(x = normal_t, 
                     y = one_hot_meta_dat,
                     family = "multinomial", 
                     type.multinomial = "grouped", 
                     alpha = 1) # alpha=1 : lasso

# par(mfrow=c(2,2))
# plot(cancer_fit)
```  

 



### CV  

```{r}
set.seed(100)

cv_fit <- 
cv.glmnet(x = normal_t,
          y = one_hot_meta_dat,
          family = "multinomial",
          type.multinomial = "grouped",
          alpha = 1,
          parallel = T)

# par(mfrow=c(1,1))
# plot(cv_fit)
# 
# par(mfrow=c(2,2))
# plot(cv_fit$glmnet.fit, xvar="lambda")
# plot(cv_fit$glmnet.fit, xvar="norm")
# par(mfrow=c(1,1))


cv_fit$lambda.1se
cv_fit$lambda.min
```  


## Coefficients  

```{r}
tmp_coeffs <- coef(cancer_fit, s = cv_fit$lambda.1se)

data.frame(name = tmp_coeffs[[1]]@Dimnames[[1]][tmp_coeffs[[1]]@i + 1], coefficient = tmp_coeffs[[1]]@x) -> k1

data.frame(name = tmp_coeffs[[2]]@Dimnames[[1]][tmp_coeffs[[2]]@i + 1], coefficient = tmp_coeffs[[2]]@x) -> k2

data.frame(name = tmp_coeffs[[3]]@Dimnames[[1]][tmp_coeffs[[3]]@i + 1], coefficient = tmp_coeffs[[3]]@x) -> k3

data.frame(name = tmp_coeffs[[4]]@Dimnames[[1]][tmp_coeffs[[4]]@i + 1], coefficient = tmp_coeffs[[4]]@x) -> k4


all(k1$name==k2$name)
all(k2$name==k3$name)
all(k3$name==k4$name)

k1 %>% 
  left_join(k2, by = "name") %>% 
  left_join(k3, by = "name") %>% 
  left_join(k4, by = "name")
```  

## normalized count & gene condition  


```{r}
normal_temp <- normal %>% t %>% data.frame
normal_temp[1:2,1:2]

normal_z <- scale(normal_temp, center = T, scale = T)
normal_z <- normal_z %>% t %>% data.frame
normal_z[1:2,1:2]




sig_gene <- k1 %>% 
  select(name) %>% 
  left_join(normal_z %>% rownames_to_column(var="name"), by = c("name"))

sig_gene <- sig_gene[-1,]
sig_gene[1:2,1:3]


rownames(sig_gene) <- sig_gene[,1]
sig_gene <- sig_gene[,-1]

sig_gene <- sig_gene %>% t %>% data.frame
sig_gene <- sig_gene %>% rownames_to_column(var = "name")

sig_gene$name <- gsub(pattern = "\\.",replacement = "-",x = sig_gene$name)

sig_gene <- sig_gene %>% left_join(meta_dat %>% rownames_to_column("name"), by = c("name"))

colnames(sig_gene)
```  

## Graph  

```{r}
work <- sig_gene %>% select(1:11,"condition")
work %>% colnames
sig_gene %>% dim

work[1:2,1:4]

work_temp <- 
work %>%
  pivot_longer(cols = -c(condition, name),
               names_to = "gene", values_to = "count")

work_temp %>% head

work_temp$count <- as.numeric(work_temp$count)
```  


```{r}
work_temp %>%
  ggplot(aes(x=gene,y=count,fill=condition))+
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, alpha=0.8) +
  geom_jitter(color="black", size=0.06, alpha=0.2)+
  theme_ipsum() +
  theme(
    legend.position=c(.9, .8),
    plot.title = element_text(size=11)
  ) +
  ggtitle("A boxplot by subtype") +
  xlab("") +
  ylab("Normalized Count") +
  labs(fill="Subtype") + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
```  



## Feature Selection with LASSO  

```{r}
cv_fit$lambda.min %>% log
cv_fit$lambda.1se %>% log

minus_min_lse <- 
  cv_fit$lambda.min - (cv_fit$lambda.1se - cv_fit$lambda.min)

cv_fit$lambda.min
cv_fit$lambda.1se
minus_min_lse



plot(cv_fit)
abline(v = log(minus_min_lse), col = "red", lwd = 1.5)
text(-4.5,1.4, 
     labels = glue("log Lambda = {round(log(minus_min_lse),4)}"),
     col="red")



# coef
feature_coef <- coef(cancer_fit, s = minus_min_lse)

data.frame(name = feature_coef[[1]]@Dimnames[[1]][feature_coef[[1]]@i + 1], coefficient = feature_coef[[1]]@x) -> new1

data.frame(name = feature_coef[[2]]@Dimnames[[1]][feature_coef[[2]]@i + 1], coefficient = feature_coef[[2]]@x) -> new2

data.frame(name = feature_coef[[3]]@Dimnames[[1]][feature_coef[[3]]@i + 1], coefficient = feature_coef[[3]]@x) -> new3

data.frame(name = feature_coef[[4]]@Dimnames[[1]][feature_coef[[4]]@i + 1], coefficient = feature_coef[[4]]@x) -> new4


all(new1$name==new2$name)
all(new2$name==new3$name)
all(new3$name==new4$name)

selected_dat <- 
new1 %>% 
  left_join(new2, by = "name") %>% 
  left_join(new3, by = "name") %>% 
  left_join(new4, by = "name")

selected_dat <- selected_dat[-1,] # delete intercept row
```  

## PCA with selected Genes  

```{r}
# confirm the 180 genes
normal_z %>%
  rownames_to_column(var = "name") %>% 
  .$name %in% selected_dat$name %>% sum


pca_dat <- 
normal_z[normal_z %>% rownames_to_column(var = "name") %>% 
  .$name %in% selected_dat$name, ] # (180 : genes, 630 : patients)

pca_dat[1:3,1:2]


pca_dat <- pca_dat %>% t %>% data.frame

pca_obj <- prcomp(pca_dat)
pca_obj <- as.data.frame(pca_obj$x)



theme<-
  theme(panel.background =
          element_blank(),
        panel.border=element_rect(fill=NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background=element_blank(),
        axis.text.x=element_text(colour="black"),
        axis.text.y=element_text(colour="black"),
        axis.ticks=element_line(colour="black"),
        plot.margin=unit(c(1,1,1,1),"line"),
        legend.position=c(0.85,0.8))




ggplot(pca_obj,aes(x=PC1,y=PC2, color=meta_dat$condition)) +
  geom_point() +
  theme + 
  labs(color='Subtype') 
```  

## Boruta feature selection  

```{r}
library(Boruta)
feature_dat <- pca_dat %>% bind_cols(condition = meta_dat$condition)
feature_dat$condition <- feature_dat$condition %>% as.factor


set.seed(100)
boruta_results <- Boruta(condition ~ ., 
                         data = feature_dat, 
                         maxRuns=100)


boruta_results$finalDecision %>% data.frame %>% table
plot(boruta_results, las = 1, xaxt='n')
```  

## Data  

```{r}
# data <- normal_temp[,selected_dat$name]
# data[1:2,1:2]

good_feature <- 
boruta_results$finalDecision %>% 
  data.frame %>% 
  filter(.!="Rejected") %>% 
  rownames

data <- pca_dat[, good_feature]
data[1:2,1:2]
```  


## Data partition  

```{r}
set.seed(100)
index <- createDataPartition(1:630, p = 0.8, list = F)

train_x <- data[index,]
train_y <- meta_dat[index,] 

test_x <- data[-index,]
test_y <- meta_dat[-index,]
```


## Imbalance Data  

```{r}
prop.table(table(meta_dat))
prop.table(table(train_y))
prop.table(table(test_y))

table(train_y)
```  


## Classification without sampling method  

```{r}
set.seed(100)
trControl <- trainControl(method="repeatedcv",
                          number=10,
                          repeats = 3,
                          allowParallel =TRUE)

Grid <- expand.grid(.mtry = 1:20)


rf_train <- train(x = train_x, 
                  y = train_y,
                  method = "rf",
                  tuneGrid = Grid,
                  trControl = trControl,
                  metric = "Accuracy",
                  ntree=400,
                  verbose = FALSE)
  

rf_train$bestTune

pred_original <- predict(rf_train, newdata = test_x, type="raw")


confusionMatrix(pred_original, test_y %>% as.factor)
```  

## Up & Down sampling  

```{r}
set.seed(100)
train_y <- train_y %>% data.frame(class=.)
train_y$class <- train_y$class %>% as.factor


x <- caret::upSample(x = train_x, y = train_y$class)

table(x$Class)


x2 <- caret::downSample(x = train_x, y = train_y$class)

table(x2$Class)
```  


```{r}
up_train_x <- x %>% select(-"Class")
up_train_y <- x$Class %>% as.character

down_train_x <- x2 %>% select(-"Class")
down_train_y <- x2$Class %>% as.character


train_y <- meta_dat[index,] 
```  

## SMOTE  

```{r}
data_sampling <- train_x %>% bind_cols(train_y %>%
                                         data.frame(class=.))
data_sampling$class <- data_sampling$class %>% as.factor


# sampling_rose <- ROSE(class~., data=data_sampling, seed=100)$data
# The response variable must have 2 levels : regulations
set.seed(100)
sampling_smote <- SMOTE(class~., 
                        data=data_sampling,
                        perc.over = 200,
                        perc.under = 300,
                        k = 5)
```  

```{r}
train_y %>% table
sampling_smote$class %>% table
```  



[SMOTE](https://medium.com/@hslee09/r-%EB%B6%84%EB%A5%98-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%B6%88%EA%B7%A0%ED%98%95-f5a260056049)  


## Model application  


```{r}
set.seed(100)
rf_train_under <- train(x = down_train_x,
                        y = down_train_y,
                        method = "rf",
                        tuneGrid = Grid,
                        trControl = trControl,
                        metric = "Accuracy",
                        ntree=400,
                        verbose = FALSE)
  

rf_train_under$bestTune

prediction_under <- predict(rf_train_under, newdata = test_x, type="raw")


confusionMatrix(prediction_under, test_y %>% as.factor)


## oversampling -------------------------------- 


rf_train_over  <- train(x = up_train_x,
                        y = up_train_y,
                        method = "rf",
                        tuneGrid = Grid,
                        trControl = trControl,
                        metric = "Accuracy",
                        ntree=400,
                        verbose = FALSE)
  

rf_train_over$bestTune

prediction_over <- predict(rf_train_over, newdata = test_x, type="raw")


confusionMatrix(prediction_over, test_y %>% as.factor)


# SMOTE --------------------------

rf_train_smote  <- train(x = sampling_smote %>% select(-class),
                         y = sampling_smote$class,
                         method = "rf",
                         tuneGrid = Grid,
                         trControl = trControl,
                         metric = "Accuracy",
                         ntree=400,
                         verbose = FALSE)


rf_train_smote$bestTune

prediction_smote <- predict(rf_train_smote, newdata = test_x, type="raw")


confusionMatrix(prediction_smote, test_y %>% as.factor)
```


## 일반적인 성능 평가 지표

```{r}
set.seed(100)
breast_models <- list(original = rf_train,
                      under = rf_train_under,
                      over = rf_train_over,
                      smote = rf_train_smote)

breast_resampling <- resamples(breast_models)

bwplot(breast_resampling)
```  



## Accuracy  

```{r}
# Oversampling
confusionMatrix(prediction_over %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_over %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# Undersampling
confusionMatrix(prediction_under %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_under %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# SMOTE
confusionMatrix(prediction_smote %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_smote %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# Original
confusionMatrix(pred_original %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(pred_original %>% as.factor, 
                test_y %>% as.factor)$overall[1]
```  

## GRID  

```{r}
theme_set(new = theme_bw())

p1 <- 
ggplot(rf_train) + theme(legend.position = "none",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Original Data")
  

p2 <- 
ggplot(rf_train_under) + theme(legend.position = "right",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Undersampling Data")

p3 <- 
ggplot(rf_train_over) + theme(legend.position = "none",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Oversampling Data")

p4 <- 
ggplot(rf_train_smote) + theme(legend.position = "right",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="SMOTE Data")


p1+p2+p3+p4
```  


## Multiclass ROC CURVE  

```{r}
# direction = auto


# Oversampling AUC
over_roc <- 
pROC::multiclass.roc(prediction_over %>% as.numeric(),
                     test_y %>% as.factor %>% as.numeric(),
                     direction ="<")



# Undersampling AUC
under_roc <- 
pROC::multiclass.roc(prediction_under %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")



# SMOTE AUC
smote_roc <- 
pROC::multiclass.roc(prediction_smote %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")




# Original AUC
original_roc <- 
pROC::multiclass.roc(pred_original %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")



over_roc$auc
under_roc$auc
smote_roc$auc
original_roc$auc
```  

<br>


```{r}
over_rc <- over_roc[['rocs']]
under_rc <- under_roc[['rocs']]
smote_rc <- smote_roc[['rocs']]
original_rs <- original_roc[['rocs']]

par(mfrow=c(2,2))

# over
plot.roc(over_rc[[1]], main = "ROC : Oversampling")
sapply(2:length(over_rc),function(i) lines.roc(over_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(over_roc$auc,4)}"), col="red")

# under
plot.roc(under_rc[[1]], main = "ROC : Undersampling")
sapply(2:length(under_rc),function(i) lines.roc(under_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(under_roc$auc,4)}"), col="red")

# smote
plot.roc(smote_rc[[1]], main = "ROC : SMOTE")
sapply(2:length(smote_rc),function(i) lines.roc(smote_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(smote_roc$auc,4)}"), col="red")

# original
plot.roc(original_rs[[1]], main = "ROC : Original")
sapply(2:length(original_rs),function(i) lines.roc(original_rs[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(original_roc$auc,4)}"),
     col="red")
```  

