---
title: "gene subtype classification"
author: "Jae Kwan Koo"
output:
  html_document:
    df_print: paged
    code_folding: show
    fig_height: 6
    fig_width: 10
    highlight: textmate
  word_document: default
  github_document:
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = T)
```  

## Library  

```{r warning=F, message=FALSE}
# Manipulate
library(tidyverse)
library(data.table)
library(glue)

# Model
library(glmnet)
library(caret)
library(Metrics)
library(ROSE) # rose
library(DMwR) # smote
library(ggfortify) # pca 

# Parallel
library(doParallel)

# Visualization
library(hrbrthemes)
library(viridis)
library(plotROC) # plot the ROC curve
library(pROC)
library(patchwork)
```  

```{r echo=FALSE}
load("D:/Jae Kwan/4학년여름/연구생/연구주제/glm_model_gridsearch.RData")
```  

## Parallel processing  

```{r}
doParallel::registerDoParallel(3)
```  

caret패키지의 모형개발 속도 향상을 위해 병렬처리를 이용한다.  

## One hot encoding  

```{r}
one_hot_meta_dat <- model.matrix(~.-1, meta_dat)
colnames(one_hot_meta_dat) <- one_hot_meta_dat %>% colnames %>% 
  str_remove(.,"condition")
```  

glmnet함수는 y label값을 수치로 받기 때문에 인코딩을 하는  것이 좋다.  

## GLM  

```{r}
normal_t <- normal %>% t %>% as.matrix
normal_t[1:3,1:2]
dim(normal_t)


cancer_fit <- glmnet(x = normal_t, 
                     y = one_hot_meta_dat,
                     family = "multinomial", 
                     type.multinomial = "grouped", 
                     alpha = 1) # alpha=1 : lasso

# par(mfrow=c(2,2))
# plot(cancer_fit)
```  

기존의 전처리된 형태의 데이터에 대해 유전자가 열로, 환자는 행으로 위치시킨다.  
Ridge regression은 일반적으로 변수들의 서브셋만을 포함하는 모델들을 선택하는 최상의 부분집합 선택과 전진 및 후진 단계적 선택과 달리, Ridge는 최종 모델에 p개 설명변수 모두를 포함할 것이다.(regularized parameter가 inf가 아니면 정확히 0으로 만들 수 없다.)  

Lasso는 이러한 Ridge의 단점을 극복한 기법이다.  
ridge와 같이 lasso는 계수 추정치들을 0으로 수축하지만, lasso에서 $l_1$ penalty는 hyperparameter lambda가 충분히 클 경우 계수 추정치들의 일부를 정확히 0이 되게 하는 효과를 가진다.  
**따라서, 최상의 부분집합 선택처럼 lasso는 변수 선택을 수행한다.**  

그 결과 lasso로부터 생성된 모델은 ridge regression에 의해 생성된 것보다 일반적으로 해석하기 훨씬 더 쉽다.  


### CV  

```{r}
set.seed(100)

cv_fit <- 
cv.glmnet(x = normal_t,
          y = one_hot_meta_dat,
          family = "multinomial",
          type.multinomial = "grouped",
          alpha = 1,
          parallel = T)

# par(mfrow=c(1,1))
# plot(cv_fit)
# 
# par(mfrow=c(2,2))
# plot(cv_fit$glmnet.fit, xvar="lambda")
# plot(cv_fit$glmnet.fit, xvar="norm")
# par(mfrow=c(1,1))


cv_fit$lambda.1se
cv_fit$lambda.min
```  

알맞은 lambda를 정해주기 위해 cross validation을 수행한다.  
cv.glmnet은 기본옵션으로 10-fold이다.  

[R documentation - cv.glmnet](https://www.rdocumentation.org/packages/glmnet/versions/4.0-2/topics/cv.glmnet)  


## Coefficients  

```{r}
tmp_coeffs <- coef(cancer_fit, s = cv_fit$lambda.1se)

data.frame(name = tmp_coeffs[[1]]@Dimnames[[1]][tmp_coeffs[[1]]@i + 1], coefficient = tmp_coeffs[[1]]@x) -> k1

data.frame(name = tmp_coeffs[[2]]@Dimnames[[1]][tmp_coeffs[[2]]@i + 1], coefficient = tmp_coeffs[[2]]@x) -> k2

data.frame(name = tmp_coeffs[[3]]@Dimnames[[1]][tmp_coeffs[[3]]@i + 1], coefficient = tmp_coeffs[[3]]@x) -> k3

data.frame(name = tmp_coeffs[[4]]@Dimnames[[1]][tmp_coeffs[[4]]@i + 1], coefficient = tmp_coeffs[[4]]@x) -> k4


all(k1$name==k2$name)
all(k2$name==k3$name)
all(k3$name==k4$name)

k1 %>% 
  left_join(k2, by = "name") %>% 
  left_join(k3, by = "name") %>% 
  left_join(k4, by = "name")
```  

이전에 만든 glmnet모형에 `s = `으로 원하는 lambda를 설정할 수 있다.  
다음과 같은 방법으로 4개의 subtype에 대한 coefficient를 뽑아낸다.  
여기있는 유전자들은 4개의 subtype에 하나라도 영향을 미치는 유전자라고 생각할 수 있을 것이다.  

<br>

물론 cv.glmnet에서 정한 lambda를 통해 새 모형을 만들면 `beta()`함수로 coefficient를 쉽게 뽑아낼 수도 있을 것이다.  



## normalized count & gene condition  


```{r}
normal_temp <- normal %>% t %>% data.frame
normal_temp[1:2,1:2]

normal_z <- scale(normal_temp, center = T, scale = T)
normal_z <- normal_z %>% t %>% data.frame
normal_z[1:2,1:2]




sig_gene <- k1 %>% 
  select(name) %>% 
  left_join(normal_z %>% rownames_to_column(var="name"), by = c("name"))

sig_gene <- sig_gene[-1,]
sig_gene[1:2,1:3]


rownames(sig_gene) <- sig_gene[,1]
sig_gene <- sig_gene[,-1]

sig_gene <- sig_gene %>% t %>% data.frame
sig_gene <- sig_gene %>% rownames_to_column(var = "name")

sig_gene$name <- gsub(pattern = "\\.",replacement = "-",x = sig_gene$name)

sig_gene <- sig_gene %>% left_join(meta_dat %>% rownames_to_column("name"), by = c("name"))

colnames(sig_gene)
```  

각 유전자별로 normalization을 수행한다.  

<Definition>  
Normalization is a process designed to identify and correct technical biases removing the least possible biological signal. This step is technology and platform-dependant.  


**Library size**, **genes length**는 실험에서 편향을 가져올 수 있다.  


* `genes length` : The raw count of two genes cannot be face off if gene A is twice longer than gene B. Due to its length, the longest gene will have much chance to be sequenced than the short one. And in the end, for the same expression level, the longest gene will get more read than the shortest one  

* `library size` : the most well know bias. You create two libraries for two conditions with the same RNA composition. The second library works way better than the first one, you got 12 000 000 reads for condition A and 36 000 000 reads for condition B. You will have three times (36 000 000/12 000 000 = 3) more of each RNA in your condition B than your condition A.  


다른 library size로 인해 한 sample이 다른 sample에 비해 더 많은 판독 값이 유전자에 정렬될 수 있다.  


## Graph  

```{r}
work <- sig_gene %>% select(1:11,"condition")
work %>% colnames
sig_gene %>% dim

work[1:2,1:4]

work_temp <- 
work %>%
  pivot_longer(cols = -c(condition, name),
               names_to = "gene", values_to = "count")

work_temp %>% head

work_temp$count <- as.numeric(work_temp$count)
```  


```{r}
work_temp %>%
  ggplot(aes(x=gene,y=count,fill=condition))+
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE, alpha=0.8) +
  geom_jitter(color="black", size=0.06, alpha=0.2)+
  theme_ipsum() +
  theme(
    legend.position=c(.9, .8),
    plot.title = element_text(size=11)
  ) +
  ggtitle("A boxplot by subtype") +
  xlab("") +
  ylab("Normalized Count") +
  labs(fill="Subtype") + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
```  

4개의 subtype중 하나라도 영향을 미치는 유전자 중 10개에 대해 나타낸 시각화이다.  

<br>

이제 4개의 유방암 아형을 classify하는 모형을 구축해보기로 한다.  


## Feature Selection with LASSO  

```{r}
cv_fit$lambda.min %>% log
cv_fit$lambda.1se %>% log

minus_min_lse <- 
  cv_fit$lambda.min - (cv_fit$lambda.1se - cv_fit$lambda.min)

cv_fit$lambda.min
cv_fit$lambda.1se
minus_min_lse



plot(cv_fit)
abline(v = log(minus_min_lse), col = "red", lwd = 1.5)
text(-4.5,1.4, 
     labels = glue("log Lambda = {round(log(minus_min_lse),4)}"),
     col="red")



# coef
feature_coef <- coef(cancer_fit, s = minus_min_lse)

data.frame(name = feature_coef[[1]]@Dimnames[[1]][feature_coef[[1]]@i + 1], coefficient = feature_coef[[1]]@x) -> new1

data.frame(name = feature_coef[[2]]@Dimnames[[1]][feature_coef[[2]]@i + 1], coefficient = feature_coef[[2]]@x) -> new2

data.frame(name = feature_coef[[3]]@Dimnames[[1]][feature_coef[[3]]@i + 1], coefficient = feature_coef[[3]]@x) -> new3

data.frame(name = feature_coef[[4]]@Dimnames[[1]][feature_coef[[4]]@i + 1], coefficient = feature_coef[[4]]@x) -> new4


all(new1$name==new2$name)
all(new2$name==new3$name)
all(new3$name==new4$name)

selected_dat <- 
new1 %>% 
  left_join(new2, by = "name") %>% 
  left_join(new3, by = "name") %>% 
  left_join(new4, by = "name")

selected_dat <- selected_dat[-1,] # delete intercept row
```  

이전에 영향을 미치는 유전자를 찾을때보다는 덜 엄격하게 lambda를 잡아 유전자 변수들이 조금 더 많이 선택될 수 있게 했다.  

여기서 정하게 된 lambda의 기준점은 cv.glmnet()에서 도출된 Lasso모형의 lambda minimun과 lambda first standard error의 차이만큼 lambda minimun을 중심으로 반대로 이동한 lambda의 값(lambda minimum - (lambda first se - lambda min)을 취하였다.  

## PCA with selected Genes  

```{r}
# confirm the 180 genes
normal_z %>%
  rownames_to_column(var = "name") %>% 
  .$name %in% selected_dat$name %>% sum


pca_dat <- 
normal_z[normal_z %>% rownames_to_column(var = "name") %>% 
  .$name %in% selected_dat$name, ] # (180 : genes, 630 : patients)

pca_dat[1:3,1:2]


pca_dat <- pca_dat %>% t %>% data.frame

pca_obj <- prcomp(pca_dat)
pca_obj <- as.data.frame(pca_obj$x)



theme<-
  theme(panel.background =
          element_blank(),
        panel.border=element_rect(fill=NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background=element_blank(),
        axis.text.x=element_text(colour="black"),
        axis.text.y=element_text(colour="black"),
        axis.ticks=element_line(colour="black"),
        plot.margin=unit(c(1,1,1,1),"line"),
        legend.position=c(0.85,0.8))




ggplot(pca_obj,aes(x=PC1,y=PC2, color=meta_dat$condition)) +
  geom_point() +
  theme + 
  labs(color='Subtype') 
```  

정해진 유전자들을 PCA로 살펴보자  
이전에 37600개를 모두 사용한 것보다 더 잘 분리될 것 같다.  

## Boruta feature selection  

```{r}
library(Boruta)
feature_dat <- pca_dat %>% bind_cols(condition = meta_dat$condition)
feature_dat$condition <- feature_dat$condition %>% as.factor


set.seed(100)
boruta_results <- Boruta(condition ~ ., 
                         data = feature_dat, 
                         maxRuns=100)


boruta_results$finalDecision %>% data.frame %>% table
plot(boruta_results, las = 1, xaxt='n')
```  

덜 엄격하게 정해진 유전자변수들로부터 한번 더 걸러내는 작업을 가졌다.  

<br>

많은 변수들을 가지는 고차원 데이터는 기계학습문제에서 요즘 증가하는 추세이다. 이 큰 데이터로부터 유용한 정보를 추출하기 위해, 우리는 noise, redundant를 줄이기 위해 통계적 테크닉을 사용해야 한다.  
왜냐하면, 우리는 모형을 훈련시키기 위해 우리의 처리에서 모든 변수들을 사용하지는 않을 것이기 때문인데, 여기서 **Feature Selection**이 중요한 역할을 한다.  

모형 훈련을 더 빠르게 해주고 모형의 복잡도를 낮춰 더 쉽게 이해할 수 있고, accuracy, precision, recall등 모형 평가의 척도를 향상시킬 수 있다.  


<br>

<Boruta algorithm>  

Boruta는 데이터 셋에서 변수들의 중요성에 대한 것들을 요청한다.  
많든 변수들은 중요한지, 안중요한지, 잠정적인지 분류가 된다.  

Tentative features들은 그들의 shadow features라는 것에 가까운 특성을 가져, random forest 실행횟수로는 확신있게 중요한 변수인지 아닌지 결정할 수 없는 변수들을 말한다.  

`maxRuns = `를 증가시킴에 따라 tentative features이 남아있는지 여부를 고려할 수 있다.  

rf 분류자는 out of bag error의 값이 최소화되는 곳에서 수렴한다.  

X축은 변수들을 나타내고, Y축은 섞인 데이터에서 모든 변수들의 Z-score가 위치해 변수의 중요도를 나타낸다.  



<br>


* out of bag error : an estimate to measure prediction error of the classifiers which uses bootstrap aggregation to sub sample data samples used for training.  

* 보루타 알고리즘은 filter method보다 더 많은 연산이 요구되는 wrapper method알고리즘이다.  

* Boruta알고리즘은 rf를 구현한 wrapper이다.  

* rf algorithm에서는 평균과 표준편차를 이용한 z score를 활용하지 않는데, 분포가 normal(0,1)을 따르지 않으므로 변수 중요성에 대한 통계적 유의성과 직접적인 관련이 없기 때문이다.  

* Boruta algorithm은 rf내의 tree에서 평균 정확도 손실의 fluctuation을 고려하기 위해 중요성을 측정할 때 z-score을 사용한다.  




## Data  

```{r}
# data <- normal_temp[,selected_dat$name]
# data[1:2,1:2]

good_feature <- 
boruta_results$finalDecision %>% 
  data.frame %>% 
  filter(.!="Rejected") %>% 
  rownames

data <- pca_dat[, good_feature]
data[1:2,1:2]
```  


## Data partition  

```{r}
set.seed(100)
index <- createDataPartition(1:630, p = 0.8, list = F)

train_x <- data[index,]
train_y <- meta_dat[index,] 

test_x <- data[-index,]
test_y <- meta_dat[-index,]
```  

train과 test의 비율을 80대 20으로 분리한다.  
caret::createDataPartition은 기본적으로 각 클래스별 층화추출을 수행한다.  

## Imbalance Data  

```{r}
prop.table(table(meta_dat))
prop.table(table(train_y))
prop.table(table(test_y))

table(train_y)
```  

각 클래스에서 비슷한 갯수들로 추출됨을 확인  
LuminalA가 극히 많은 Imbalance data이다.  

original 데이터와 3개의 sampling method을 실행한 데이터와의 모형을 적합해 확인해보도록 한다.   

sampling method별로 비교할 것이므로 모두 rf모형을 사용했고, tree갯수는 400으로 고정시켰다. mtry만 Grid Search로 탐색하였다.  
10-fold 3 repeat cross validation을 수행  

## Classification without sampling method  

```{r}
set.seed(100)
trControl <- trainControl(method="repeatedcv",
                          number=10,
                          repeats = 3,
                          allowParallel =TRUE)

Grid <- expand.grid(.mtry = 1:20)


rf_train <- train(x = train_x, 
                  y = train_y,
                  method = "rf",
                  tuneGrid = Grid,
                  trControl = trControl,
                  metric = "Accuracy",
                  ntree=400,
                  verbose = FALSE)
  

rf_train$bestTune

pred_original <- predict(rf_train, newdata = test_x, type="raw")


confusionMatrix(pred_original, test_y %>% as.factor)
```  

## Up & Down sampling  

```{r}
set.seed(100)
train_y <- train_y %>% data.frame(class=.)
train_y$class <- train_y$class %>% as.factor


x <- caret::upSample(x = train_x, y = train_y$class)

table(x$Class)


x2 <- caret::downSample(x = train_x, y = train_y$class)

table(x2$Class)
```  


```{r}
up_train_x <- x %>% select(-"Class")
up_train_y <- x$Class %>% as.character

down_train_x <- x2 %>% select(-"Class")
down_train_y <- x2$Class %>% as.character


train_y <- meta_dat[index,] 
```  

## SMOTE  

```{r}
data_sampling <- train_x %>% bind_cols(train_y %>%
                                         data.frame(class=.))
data_sampling$class <- data_sampling$class %>% as.factor


# sampling_rose <- ROSE(class~., data=data_sampling, seed=100)$data
# The response variable must have 2 levels : regulations
set.seed(100)
sampling_smote <- SMOTE(class~., 
                        data=data_sampling,
                        perc.over = 200,
                        perc.under = 300,
                        k = 5)
```  

비율은 경험적으로 선택하였다.  

```{r}
train_y %>% table
sampling_smote$class %>% table
```  



[SMOTE](https://medium.com/@hslee09/r-%EB%B6%84%EB%A5%98-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%B6%88%EA%B7%A0%ED%98%95-f5a260056049)  


## Model application  


```{r}
set.seed(100)
rf_train_under <- train(x = down_train_x,
                        y = down_train_y,
                        method = "rf",
                        tuneGrid = Grid,
                        trControl = trControl,
                        metric = "Accuracy",
                        ntree=400,
                        verbose = FALSE)
  

rf_train_under$bestTune

prediction_under <- predict(rf_train_under, newdata = test_x, type="raw")


confusionMatrix(prediction_under, test_y %>% as.factor)


## oversampling -------------------------------- 


rf_train_over  <- train(x = up_train_x,
                        y = up_train_y,
                        method = "rf",
                        tuneGrid = Grid,
                        trControl = trControl,
                        metric = "Accuracy",
                        ntree=400,
                        verbose = FALSE)
  

rf_train_over$bestTune

prediction_over <- predict(rf_train_over, newdata = test_x, type="raw")


confusionMatrix(prediction_over, test_y %>% as.factor)


# SMOTE --------------------------

rf_train_smote  <- train(x = sampling_smote %>% select(-class),
                         y = sampling_smote$class,
                         method = "rf",
                         tuneGrid = Grid,
                         trControl = trControl,
                         metric = "Accuracy",
                         ntree=400,
                         verbose = FALSE)


rf_train_smote$bestTune

prediction_smote <- predict(rf_train_smote, newdata = test_x, type="raw")


confusionMatrix(prediction_smote, test_y %>% as.factor)
```


## 일반적인 성능 평가 지표

```{r}
set.seed(100)
breast_models <- list(original = rf_train,
                      under = rf_train_under,
                      over = rf_train_over,
                      smote = rf_train_smote)

breast_resampling <- resamples(breast_models)

bwplot(breast_resampling)
```  

Setting the seed produces paired samples and enables the two models to be compared using the resampling technique described in Hothorn at al, "The design and analysis of benchmark experiments", Journal of Computational and Graphical Statistics(2005)  

<br>

$$
\kappa = {P(a)-P(e) \over 1- P(e)}
$$  
P(e) : expected accuracy  
P(a) : observed accuracy  

즉, 실제 정확도와 예측된 정확도를 구분지어 위의 식으로 구한 수치가 Kappa 통계량이다.  

Kappa 통계량은 -1부터 1까지의 값을 가지는데, 0의 값을 가지게 되면 관측된 클래스와 예측된 클래스 사이의 합의점이 전혀 없음을 의미한다.  
결론적으로 Kappa값이 클수록 좋다.  





## Accuracy  

```{r}
# Oversampling
confusionMatrix(prediction_over %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_over %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# Undersampling
confusionMatrix(prediction_under %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_under %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# SMOTE
confusionMatrix(prediction_smote %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(prediction_smote %>% as.factor, 
                test_y %>% as.factor)$overall[1]


# Original
confusionMatrix(pred_original %>% as.factor, 
                test_y %>% as.factor)$table
confusionMatrix(pred_original %>% as.factor, 
                test_y %>% as.factor)$overall[1]
```  

## GRID  

```{r}
theme_set(new = theme_bw())

p1 <- 
ggplot(rf_train) + theme(legend.position = "none",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Original Data")
  

p2 <- 
ggplot(rf_train_under) + theme(legend.position = "right",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Undersampling Data")

p3 <- 
ggplot(rf_train_over) + theme(legend.position = "none",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="Oversampling Data")

p4 <- 
ggplot(rf_train_smote) + theme(legend.position = "right",
                          legend.direction = "vertical") +
  labs(title="Grid Search", subtitle="SMOTE Data")


p1+p2+p3+p4
```  

```{r}
grid_data <- data.frame(rf_train$results[1:2],
                        rf_train_over$results[1:2],
                        rf_train_under$results[1:2],
                        rf_train_smote$results[1:2])
 
ggplot(grid_data, aes(x = mtry)) + 
  geom_point(aes(y = Accuracy, colour = "Original Data")) + 
  geom_line(aes(y = Accuracy, colour = "Original Data")) + 
  
  geom_point(aes(y = Accuracy.1, colour = "Oversampling Data")) +
  geom_line(aes(y = Accuracy.1, colour = "Oversampling Data")) + 
    
  geom_point(aes(y = Accuracy.2, colour = "Undersampling Data")) +
  geom_line(aes(y = Accuracy.2, colour = "Undersampling Data")) + 
    
  geom_point(aes(y = Accuracy.3, colour = "SMOTE Data")) +
  geom_line(aes(y = Accuracy.3, colour = "SMOTE Data")) + 
  
  
  
  scale_x_continuous(breaks=seq(0,20,4)) +
  scale_y_continuous(breaks=seq(0.85,1,0.02)) + 
  theme(legend.title=element_blank(),
        legend.position = "bottom") + 
  ggtitle("Grid Search for sampling methods")
```  



## Multiclass ROC CURVE  

```{r}
# direction = auto


# Oversampling AUC
over_roc <- 
pROC::multiclass.roc(prediction_over %>% as.numeric(),
                     test_y %>% as.factor %>% as.numeric(),
                     direction ="<")



# Undersampling AUC
under_roc <- 
pROC::multiclass.roc(prediction_under %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")



# SMOTE AUC
smote_roc <- 
pROC::multiclass.roc(prediction_smote %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")




# Original AUC
original_roc <- 
pROC::multiclass.roc(pred_original %>% as.factor %>% as.numeric,
                     test_y %>% as.factor %>% as.numeric,
                     direction ="<")



over_roc$auc
under_roc$auc
smote_roc$auc
original_roc$auc
```  

<br>


```{r}
over_rc <- over_roc[['rocs']]
under_rc <- under_roc[['rocs']]
smote_rc <- smote_roc[['rocs']]
original_rs <- original_roc[['rocs']]

par(mfrow=c(2,2))

# over
plot.roc(over_rc[[1]], main = "ROC : Oversampling")
sapply(2:length(over_rc),function(i) lines.roc(over_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(over_roc$auc,4)}"), col="red")

# under
plot.roc(under_rc[[1]], main = "ROC : Undersampling")
sapply(2:length(under_rc),function(i) lines.roc(under_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(under_roc$auc,4)}"), col="red")

# smote
plot.roc(smote_rc[[1]], main = "ROC : SMOTE")
sapply(2:length(smote_rc),function(i) lines.roc(smote_rc[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(smote_roc$auc,4)}"), col="red")

# original
plot.roc(original_rs[[1]], main = "ROC : Original")
sapply(2:length(original_rs),function(i) lines.roc(original_rs[[i]],col=i))
text(0,0.2,labels=glue("AUC : {round(original_roc$auc,4)}"),
     col="red")
```  

<br>
<br>


## Reference  

[multiclass ROC curve](https://stackoverflow.com/questions/34169774/plot-roc-for-multiclass-roc-in-proc-package)  

[Boruta algorithm](https://www.datacamp.com/community/tutorials/feature-selection-R-boruta#package)  



